---
output: html_document 
---

# Reproduction of Malcomb et al (2014)

#### Malcomb, D. W., E. A. Weaver, and A. R. Krakowka. 2014. Vulnerability modeling for sub-Saharan Africa: An operationalized approach in Malawi. Applied Geography 48:17-30.

#### [https://doi.org/10.1016/j.apgeog.2014.01.004]([https://doi.org/10.1016/j.apgeog.2014.01.004)

### Authors: Kufre Udoh, Drew An-Pham, Joseph Holler, and Middlebury College Fall 2019 + Spring 2021 Geography 323 Class

### [https://gis4dev.github.io/](https://gis4dev.github.io/)


```{r libraries, include = F}
packages = c("downloader", "haven", "stars", "dplyr", "sf", "rdhs", "classInt", "readr", "ggplot2", "here", "s2", "pastecs", "cartography")
setdiff(packages, rownames(installed.packages()))
install.packages(setdiff(packages, rownames(installed.packages())), quietly=TRUE)

library(downloader)
library(haven)
library(sf)
library(stars)
library(dplyr)
library(here)
library(classInt)
library(rdhs)
library(readr)
library(ggplot2)
library(s2)
library(pastecs)
library(cartography)

sf_use_s2(T)
```

```{r formatting package versions}
# list of required packages
packages = c("here")

# load and install required packages
package.check <- lapply(
  packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)
      library(x, character.only = TRUE)
    }
  }
)

# save the R processing environment 
writeLines(capture.output(sessionInfo()),here("procedure","environment","r_environment.txt"))

# read in R processing environment
# the data frame package_version provides info on the libraries used for this analysis when previewed in the console
package_version <- read.delim(here("procedure","environment","r_environment.txt"))
```

```{r create values to access private and public raw data more efficiently}
private_r = here("data","raw","private")
public_r = here("data","raw","public")
```

```{r reading all data used for analysis, message=FALSE}
ta_gref = read_sf(here("data", "derived", "public", "ta_fig4_v.gpkg"), layer = "ta_fig4_v") %>% 
  st_make_valid()
# This read may need to be changed to match the final output of 01-preanalysis!
# which was: st_write(ta_v, here("data", "derived", "public", "ta_v.gpkg"), append=FALSE)

dr = read_stars(here(public_r, "dr1010ipeykx.tif")) %>% 
  st_set_crs(4326) 

fl = read_stars(here(public_r,  "fl1010irmt.tif")) %>% 
  st_set_crs(4326) 

lhz_v = read_sf(here(public_r, "MW_LHZ_2009.shp")) %>% 
  st_make_valid()

lhz_t = read.csv(here(private_r, "lhz.csv"))

ta = read_sf(here(public_r, "MWI_adm2.shp")) %>%
  st_make_valid() 

lakes = st_as_sf(read_csv(here(public_r, "major_lakes.csv"))[, c("name", "the_geom")],
                 wkt = "the_geom",
                 crs = 4326) %>%
  st_geometry %>%
  st_union %>%
  st_sf %>%
  mutate(EA = "Major Lakes of Malawi")
```

```{r reading 2010 adaptive capacity data}
dhsclusters_2010 = readRDS(here(private_r, "datasets", "MWGE62FL.rds")) %>%
  as("sf") %>% 
  st_transform(3395) %>% 
  # joining id for traditional authorities and livelihood zones to dhs clusters
  st_join(st_transform(select(ta_gref, ID_2),3395)) %>% 
  st_join(st_transform(select(lhz_v, FNID),3395)) %>% 
  rename(ta_id = ID_2,
         lhz_id = FNID,
         urban_rural = URBAN_RURA)

dhshh_2010 = readRDS(here(private_r, "datasets", "MWHR61SV.rds")) %>% zap_labels()
```

```{r households to remove}
rmv_2010 = dhshh_2010 %>%  
  filter(
  HV246A == 98 |
    HV246A == 99 |
    HV246D == 98 |
    HV246D == 99 |
    HV246E == 98 |
    HV246E == 99 |
    HV246G == 98 |
    HV246G == 99 |
    HV219  == 9 |
    HV243A == 9 |
    HV245  == 99 |
    HV206  == 9 |
    HV204  == 999 |
    HV204  == 998 |
    HV226  == 99 |
    HV226  == 95 |
    HV226  == 96 |
    HV207  ==  9 
) %>% 
  pull(HHID)
```

```{r capacity in households 2010}
hh_capacity_t = dhshh_2010 %>%
  # joining traditional authority ids and urban_rural column 
  left_join(st_drop_geometry(select(dhsclusters_2010, DHSCLUST, ta_id, urban_rural)), by = c("HV001" = "DHSCLUST")) %>%
  select(
    HHID,
    HV001,
    HV002,
    ta_id,
    urban_rural,
    HV246A,
    HV246D,
    HV246E,
    HV246G,
    HV248,
    HV245,
    HV271,
    HV251,
    HV204,
    HV206,
    HV226,
    HV219,
    HV243A,
    HV207
    #24825 features
  ) %>%
  # removing values based on index and where there are NAs 
  filter(!HHID %in% rmv_2010) %>% 
  filter(!is.na(ta_id)) %>% 
  # 23544 features of 19 variables 
  # removing any surveys where all livestock values were NA
  filter(!(is.na(HV246A) & is.na(HV246D) & is.na(HV246E)  & is.na(HV246G) )) %>% 
  # 23543 features of 19 variables 
  # using rowwise() to find sum of livestock by household --> go through every row of table
  # and calulate something for each one
  rowwise %>%
  mutate(hhlivestock = sum(HV246A, HV246D, HV246E, HV246G, na.rm = T)) %>%
  ungroup %>%
  # using percent_rank(), those  
  # in cases where desc() is used, having a greater value before ranked makes a household more vulnerable 
  mutate(
    livestock = percent_rank(hhlivestock) * 4,
    sick = percent_rank(desc(HV248)) * 4,
    land = percent_rank(HV245) * 4,
    wealth = percent_rank(HV271) * 4,
    orphans = percent_rank(desc(HV251)) * 4,
    # changing 996 to 0 as it takes no time to get water on premises
    # femalehh male = 1, female = 2, run 0 to 1.128 is the binary
    HV204 = ifelse(HV204 == 996, 0, HV204), #996 means they have source of water in proximity to home
    water = percent_rank(desc(HV204)) * 4,
    electricity = percent_rank(HV206) * 4,
    cooking = percent_rank(desc(HV226)) * 4,
    femalehh = percent_rank(desc(HV219)) * 4,
    cellphone = percent_rank(desc(HV243A)) * 4,
    radio = percent_rank(HV207) * 4,
    urbanruralscore = ifelse(urban_rural == "U", 4, 0)
    # percent_rank sets values 0 to 1, then * 4 puts everything on a 0-4 scale
  ) 
```

```{r capacity for traditional authorities 2010 at the household level}
hh_capacity_t <- hh_capacity_t %>%
  # calculating capacity scores based on Table 2 in Malcomb et al (2014)
  rowwise %>%
  mutate(
    capacity = sum(
      livestock * 0.04,
      sick * 0.03,
      land * 0.06,
      wealth * 0.04,
      orphans * 0.03,
      water * 0.04,
      electricity * 0.03,
      cooking * 0.02,
      femalehh * 0.02,
      cellphone * 0.04,
      radio * 0.03,
      urbanruralscore * 0.02),
      # NAs are not removed here to filter out incomplete surveys later on
      # multiple by ratio that adds everything to 40% of 5 --> max is going to be 2, 2*20 = 40%
      # values have possible range of 0 to 1.6, 0.071 to 1.054 when adjusted range of 0-4
      na.rm = F)
      # 23543 features of 34 variables 
```

``` {r summary stats for tas at hh level before pullings nas}
hh_stats <- stat.desc(hh_capacity_t[,21:33]) %>%
  mutate_if(is.numeric, round, digits=1)
hh_stats
```

```{r extract traditional authorities without data}
hh_null <- hh_capacity_t[is.na(hh_capacity_t$capacity),] 

st_write(hh_null, here("data", "derived", "public", "hh_null.csv"), append=FALSE)
# 3981 features
```

```{r remove nulls}
hh_capacity_t <- hh_capacity_t %>%
filter(!is.na(capacity)) %>% # removing incomplete surveys 
ungroup
#19562 features (from the initial 23543 --> removed 3981 NA features)
```

``` {r summary stats for tas at hh level after pullings nas}
hh_capacity_stats <- stat.desc(hh_capacity_t[,21:33]) %>%
  mutate_if(is.numeric, round, digits=1)
hh_capacity_stats
```

```{r capacity for traditional authorities 2010; aggregates from household level}
  ta_capacity_t <- hh_capacity_t %>% 
  group_by(ta_id) %>%
  summarize(
    capacity_avg = mean(capacity),
    capacity_min = min(capacity),
    capacity_max = max(capacity),
    capacity_sd = sd(capacity)
  )
#214 features
```

```{r joining 2010 capacity to ta and creating breaks for visualization}
# join mean capacity to traditional authorities
ta_v = left_join(
  ta_gref,
  select(ta_capacity_t, ta_id, capacity_2010 = capacity_avg),
  by = c("ID_2" = "ta_id")
)

# making capacity score resemble malcomb et al's work 
ta_v = mutate(ta_v, capacity_2010 = capacity_2010 * 25)
# 234 features 

# preparing breaks for mapping using natural jenks method
ta_brks = filter(ta_v, !is.na(capacity_2010)) %>% {classIntervals(.$capacity_2010, 4, style = "jenks")$brks}

ta_int = lapply(1:4, function(x) paste0(round(ta_brks[x],2)," - ", round(ta_brks[x +1],2))) %>% unlist()

ta_v = mutate(ta_v, capacity_2010_brks = case_when(
  capacity_2010 <= ta_brks[2] ~ ta_int[1],
  capacity_2010 <= ta_brks[3] ~ ta_int[2],
  capacity_2010 <= ta_brks[4] ~ ta_int[3],
  capacity_2010 >  ta_brks[4] ~ ta_int[4]
))
```

```{r extract traditional authorities without data by capacity, warning=FALSE}
ta_null_cap <- ta_v[is.na(ta_v$capacity_2010),]
#20 features

st_write(ta_null_cap, here("data", "derived", "public", "ta_null_capacity.shp"), append=FALSE)
```

```{r saving adaptive capacity scores}
save(
  ta_capacity_t,
  file = here("data", "derived", "public", "adaptive_capacity.rData")
)
```

```{r check final ta_v output before mapping}
ta_v_check <- ggplot() + 
  geom_sf(data = ta_v,
          aes(fill = capacity_2010), size = .1, color = "grey98") + 
          scale_fill_continuous(name = "Adaptive Capacity Scores", low="lemonchiffon1", high="lightcoral", na.value = "snow3") 
ta_v_check 
```

```{r cleaning and reprojecting rasters}
# creating blank raster in extent
# extent of the raster layers
# units used for bounding box = decimal degrees, long-lat
b = st_bbox(
  c(
    xmin = 35.9166666666658188,
    xmax = 32.6666666666658330,
    ymin = -9.3333333333336554,
    ymax = -17.0833333333336270
  ),
  crs = st_crs(4326)
) %>%
  st_as_sfc()

# where raster = 1, you have flood visualized
blank = st_as_stars(st_bbox(b), dx = 0.041667, dy = 0.041667)
blank[[1]][] = NA

# reprojecting, clipping, and resampling rasters to new extent and cell size
# use bilinear for drought to average continuous population exposure values (resampling?)
# (object, destination, logical operator, usable b/c of GDAL)
dr = st_warp(dr, blank, use_gdal = T, method = "bilinear")
# use nearest neighbor for flood risk to preserve integer values
fl = st_warp(fl, blank, method = "near")  

# removing factors from fl
# You can use double brackets to select elements in more or less the same way as single brackets. The difference between single and double is that with double brackets any element names are not displayed.
# rasters are a raised matrix (multiple layer) access first level of the array, second bracket editing values into the array
nmrc = as.numeric(levels(fl[[1]]))[fl[[1]]]
fl = blank
# single bracket gives you meta data (first layer), double brackets gives it to you as a matrix
fl[[1]][] = nmrc
```

```{r rasterizing geometries}
# clipping traditional authorities with livelihood zones in order to remove lake and existing null values
# building a clip function in R [x,y are parameters]
st_clip = function(x,y) st_intersection(x, st_union(st_geometry(y)))

st_agr(ta_v) = "constant"

#creates a small buffer around the Livelihood Zones & use this as a mask to clip features from Traditional Authorities (only the TAs that have data clipped to the extent of Malawi)
ta_capacity_v = st_clip(st_transform(filter(ta_v, is.na(capacity_2010) == F), 3395), st_buffer(st_transform(lhz_v, 3395), .01)) %>%
  st_transform(4326)
# 214 features 

# making capacity rasters 
ta_capacity_r = st_rasterize(ta_capacity_v[, 'capacity_2010'], blank)
```

```{R processing + weighting FEWSNet Data}
# LHZ Data
lhz_sensitivity_v  = lhz_v %>%
  inner_join(lhz_t, by = ("LZCODE" = "LZCODE")) %>%
  # calculate scores for LHZ weighted indicators by metatheme (as seen in Table 2)
  mutate(
  pctOwnCrop = (sof_crop + sof_livestock) * 100, 
  pctIncWage = (soc_labour / soc_total) * 100,
  pctIncCashCrops = (cp_tobacco + cp_sugar + cp_tea + cp_coffee) / soc_total * 100,
  disasterCoping = (se_firewoord + se_grass	+ se_wildfood + se_charcoal + se_matmaking + se_basket) / soc_total * 100,
  ) %>%
  # multiply metatheme values by 4 readjust range
  mutate(
  ownCrop = percent_rank(pctOwnCrop) * 4, # high values means lower sensitivity 
  wageIncome = percent_rank(pctIncWage) * 4, # high values means lower sensitivity
  cashCropIncome = percent_rank(desc(pctIncCashCrops)) * 4, #high values mean lower sensitivity (b/c of desc)
  newDisaster = percent_rank(desc(disasterCoping)) * 4, #high values mean lower sensitivity (b/c of desc)
  ) %>%
  rowwise %>%
  mutate(
    livelihoodSensitivity_new = sum(
      ownCrop * 6,
      wageIncome * 6,
      cashCropIncome * 4,
      newDisaster * 4) 
  ) %>% ungroup
# livelihood sensitivity range is now 23.529 to 56.000
# making capacity rasters 

lhz_sensitivity_r = st_rasterize(lhz_sensitivity_v[,'livelihoodSensitivity_new'], blank)

lhz_v_check <- ggplot() + 
  geom_sf(data = lhz_sensitivity_v, 
          aes(fill = livelihoodSensitivity_new), size = .2, color = "grey4") +
  scale_fill_continuous(name = "Livelihood Sensitivity Scores", low="lemonchiffon1", high="lightcoral")
lhz_v_check
```

```{r summary table with lhz data}
lhz_stats <- st_drop_geometry(lhz_sensitivity_v[,14:36]) %>%
  stat.desc() %>%
  mutate_if(is.numeric, round, digits=1)
lhz_stats
```

```{r function to calculate vulnerability}
  # creating mask layer
  mask = ta_capacity_r
  mask[mask > 0] = 1
  mask[mask == 0] = NA
  
  # masking flood and drought 
  #reclassify drought & flood already has classification
  #we want flood to have 20% weight so we multiply by 5, as is the data has a range of 0-4
  flood = fl * mask * 5
  drought = dr * mask
  
  # makes a list of quintile break points
  qt = quantile(drought[[1]], probs = seq(0, 1, 0.2), na.rm = T)
  
  # reclassifying drought layer using break points from 0 to 4
  # 4 * 5 = 20, match 20% weighting of exposition to drought events
  drought = drought %>%
    mutate(
      recoded = case_when(
        drought[[1]] <= qt[[2]] ~ 0,
        drought[[1]] <= qt[[3]] ~ 1,
        drought[[1]] <= qt[[4]] ~ 2,
        drought[[1]] <= qt[[5]] ~ 3,
        drought[[1]] > qt[[5]] ~ 4
      )
    ) %>% select(recoded) * 5
  
  # final output (adding component rasters)
  final = 100 - (ta_capacity_r + lhz_sensitivity_r + (40 - (drought + flood))) # 100 = highest vulnerability, 0 = lowest vulnerability
```

```{r descriptive stats for raster inputs}
fl_stats <- stat.desc(fl)
dr_stats <- stat.desc(dr)
fl_stats
dr_stats
```

```{r creating final vulnerability layers}
ta_capacity_v <- st_make_valid(ta_capacity_v) # new version of sf (1.0.0) produces error, so st_make_valid fixes spherical geom errors

ta_capacity_v$vuln = aggregate(final,ta_capacity_v,mean)$capacity_2010 

# rasterize 
ta_r = ta_capacity_v[!is.na(ta_capacity_v$vuln), "vuln"]
ta_r = st_rasterize(ta_r[1])
```

```{r extract traditional authorities without data by vuln, warning=FALSE}
ta_null <- ta_capacity_v[is.na(ta_capacity_v$vuln),]
#20 features

st_write(ta_null, here("data", "derived", "public", "ta_null.shp"), append=FALSE)
```

```{r misc. map features}
#ea used to retrieve national parks (conservation areas) + lakes
ea = lhz_v %>%
  st_transform(3395) %>%  #transform to world mercator (jh: not sure if we need to transform to 3395 and back here?)
  summarize %>%  
  st_geometry %>%  #dissolve to one feature / one geometry
  st_intersection(st_geometry(st_transform(ta, 3395))) %>%   #intersect with traditional authorities to clip them
  st_transform(4326) %>%
  st_sf %>%   #make into new simple features data frame
  mutate(EA = case_when(
    grepl("Reserve", ta[["NAME_2"]]) | grepl("Park", ta[["NAME_2"]]) ~ "National Parks and Reserves",
    T ~ "Missing Data") # search and replace names anything with Reserve or Park in the name becomes National Parks and Reserves
  ) %>%
  rbind(lakes) %>%
  st_make_valid()
```

```{r 2010 adaptive capacity map}
map_2010 = ggplot() +
  geom_sf(data = ea,
          aes(fill = EA),
          color = NA) +
  geom_sf(
    data = ta_capacity_v,
    aes(fill = capacity_2010_brks),
    color = "white",
    lwd = .2
  ) + scale_fill_manual(
    # unique(ta_capacity_v$capacity_2010_brks) allows you to check breaks
    # map will not load unless breaks are exact
    values = list(
      "Missing Data" = "#FFC389",
      "National Parks and Reserves" = "#D9EABB",
      "Major Lakes of Malawi" = "lightblue",
      "7.43 - 9.82" = "#333333",
      "9.82 - 11.39" = "#666666",
      "11.39 - 13.6" = "#999999",
      "13.6 - 16.68" = "#CCCCCC"
    )
  ) +
  scale_x_continuous(breaks = c(33,34,35,36)) +
  labs(title = "Adaptive Capacity Scores Based on 2010 DHS Surveys in 222 Traditional Authorities") +
  theme_minimal() +
  theme(legend.title = element_blank())

map_2010
```

```{r find break & limit values for vulnerability map}
vuln_max <- max(ta_r[[1]],na.rm = TRUE)
vuln_min <- min(ta_r[[1]],na.rm = TRUE)
``` 

```{r vulnerability map}
clrs = mutate(
  ea,
  colors = case_when(
    EA == "Missing Data" ~ "#999999",
    EA == "National Parks and Reserves" ~ "#D9EABB",
    EA == "Major Lakes of Malawi" ~ "lightblue"
  )
)$colors

vuln_map = ggplot() +
  geom_sf(data = ea,
          fill = clrs,
          color = NA) +
  geom_stars(data = ta_r) +
  scale_fill_gradient(
    low = "#FFFF75",
    high = "#CF4611",
    breaks = c(vuln_min, vuln_max),
    labels = c("Lower Vulnerability", "Higher Vulnerability"),
    na.value = "transparent",
    guide = "colourbar",
    limits = c(vuln_min, vuln_max)
  ) +
  scale_x_continuous(breaks = c(33,34,35,36)) +
  labs(title = "Malawi Vulnerability to Climate Change") +
  theme_minimal() +
  theme(
    legend.title = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )

vuln_map
```

```{r saving fig 4 and 5 maps}

ggsave(
  here("results","figures","fig4rep_final.png"),
  plot = map_2010,
  width = 8.5,
  height = 11,
  units = "in"
)
ggsave(
  here("results","figures","fig5rep_final.png"),
  plot = vuln_map,
  width = 8.5,
  height = 11,
  units = "in"
)
```

```{r saving spatial data outputs}
results = here("data","derived","public","results.gpkg")

write_stars(ta_r, here("data","derived","public","ta_capacity.tif"))

write_sf(ta_capacity_v, results, "ta_capacity_v")

write_sf(lhz_v, results, "lhz")
```

```{R Sample Code for Comparing Discrete Choropleth Maps, warning=FALSE}
or_fig4 = # load original figure 4 data
  read_sf(here("data", "derived", "public", "ta_fig4_v.gpkg"), 
          layer="ta_fig4_v") %>% 
  # load ta_resilience layer from georeferencing geopackage
  st_drop_geometry() %>%
  # remove the geometry data because two geometries cannot be joined
  select(c(ID_2,capacity)) %>%  
  # select only the ID_2 and resilience columns
  na.omit()
  # remove records with null values

rp_fig4 = ta_capacity_v %>% # prepare our reproduction of figure 4 data
  select(c(ID_2,capacity_2010)) %>%  
  # select only the ID_2 and resilience columns
  # note: geometry columns are 'sticky' -- only way to remove is st_drop_geometry()
  na.omit()  %>%
  # remove records with null values
  mutate(rp_ac = case_when(
  capacity_2010 <= ta_brks[2] ~ 1,
  capacity_2010 <= ta_brks[3] ~ 2,
  capacity_2010 <= ta_brks[4] ~ 3,
  capacity_2010 >  ta_brks[4] ~ 4
))
# code the capacity scores as integers, as we see them classified on the map. 
#ta_brks was the result of a Jenks classification, as noted on Malcomb et al's maps

fig4compare = inner_join(rp_fig4,or_fig4,by="ID_2") %>%  
  #inner join on field ID_2 keeps only matching records
  filter(rp_ac>0 & rp_ac<5 & capacity > 0 & capacity < 5)
  # keep only records with valid capacity scores

table(fig4compare$capacity,fig4compare$rp_ac)
# crosstabulation with frequencies

cor.test(fig4compare$capacity,fig4compare$rp_ac,method="spearman")
# Spearman's Rho correlation test

fig4compare = mutate(fig4compare, difference = rp_ac - capacity) 
# Calculate difference between the maps so that you can create a difference map
```
In order to compare the raster map produced with figure 5 from Malcomb et al (2014), figure 5 was georeferenced creating a ta_capacity.tif, which was then converted into polygons with the raster pixels to polygons tool. The authors used a color ramp of yellow to red in their raster map, so the best way to extract a linear relationship for comparison as we found was to add the blues and greens together in QGIS via zonal stats. After, the georeferenced TA's with color information were exported as a geopackge: georef_bg.gpkg and read into R for analysis.

```{R Sample Code for Comparing Continuous Raster Maps, warning=FALSE}
orfig5vect = 
  read_sf(here("data", "derived", "public", "georef_bg.gpkg"), 
          layer="georef_bg") %>%
  mutate(bg_mean = bmean + gmean)
# load original georeferenced figure 5 data

orfig5rast = st_rasterize(orfig5vect["bg_mean"], template=ta_r)
# convert mean of blue and green values into a raster using ta_final as a reference for raster
# extent, cell size, CRS, etc.

orfig5rast = orfig5rast %>% 
  mutate(or = 1-
           (bg_mean - min(orfig5rast[[1]], na.rm= TRUE)) /
           (max(orfig5rast[[1]], na.rm= TRUE) -
            min(orfig5rast[[1]], na.rm= TRUE)
        )
)  # or is Re-scaled from 0 to 1 with (value - min)/(max - min)
# it is also inverted, because higher blue values are less red

ta_r = ta_r %>% 
  mutate(rp =
           (vuln - min(ta_r[[1]], na.rm= TRUE)) /
           (max(ta_r[[1]], na.rm= TRUE) -
            min(ta_r[[1]], na.rm= TRUE)
        )
)  # rp is Re-scaled from 0 to 1 with (value - min)/(max - min)

fig5comp = c( select(ta_r,"rp"), select(orfig5rast,"or"))
# combine the original (or) fig 5 and reproduced (rp) fig 5

fig5comp = fig5comp %>% mutate( diff = rp - or )
# calculate difference between the original and reproduction,
# for purposes of mapping

fig5comppts = st_as_sf(fig5comp)
# convert raster to vector points to simplify plotting and correlation testing

plot(fig5comppts$or, fig5comppts$rp, xlab="Original Study", ylab="Reproduction")
title("Comparing Vulnerability Scores")
# create scatterplot of original results and reproduction results

cor.test(fig5comppts$or, fig5comppts$rp, method="spearman")
# Spearman's Rho correlation test

# Hint for mapping raster results: refer to the diff raster attribute
# in the fig5comp stars object like this: fig5comp["diff"]
```

```{r 2010 adaptive capacity difference map}
ac_diff_map = ggplot() +
  geom_sf(data = ea,
          aes(fill = EA),
          color = NA) +
  geom_sf(
    data = fig4compare,
    aes(fill = factor(difference)),
    color = "white",
    lwd = .2
  ) + scale_fill_manual(limits = c("-2","-1","0","1","Missing Data","Major Lakes of Malawi","National Parks and Reserves"),
    values = list(
      "Missing Data" = "#FFFFFF",
      "National Parks and Reserves" = "#D9EABB",
      "Major Lakes of Malawi" = "lightblue",
      "-2" = "#e66101",
      "-1" = "#fdb863",
      "0" = "#cccccc",
      "1" = "#b2abd2"
    )
  ) +
  scale_x_continuous(breaks = c(33,34,35,36)) +
  labs(title = "Fig. 4 Replication Comparison") +
  theme_minimal() +
  theme(legend.title = element_blank())

ac_diff_map
```

```{r find break & limit values for vulnerability difference map}
abs(max(fig5comp[[3]],na.rm = TRUE))
abs(min(fig5comp[[3]],na.rm = TRUE))
range <- max(abs(max(fig5comp[[3]],na.rm = TRUE)),abs(min(fig5comp[[3]],na.rm = TRUE)))
# takes the greatest value and makes it the range
``` 

```{r vulnerability difference map}
clrs = mutate(
  ea,
  colors = case_when(
    EA == "Missing Data" ~ "#999999",
    EA == "National Parks and Reserves" ~ "#D9EABB",
    EA == "Major Lakes of Malawi" ~ "lightblue"
  
  )
)$colors
vuln_diff_map = ggplot() +
  geom_sf(data = ea,
          fill = clrs,
          color = NA) +
  geom_stars(data = fig5comp["diff"]) +
  scale_fill_gradient2(
    low = "#e9a3c9",
    high = "#beaed4",
    breaks = c(-range,range),
    labels = c("Negative Difference", "Positive Difference"),
    na.value = "transparent",
    guide = "colourbar",
    limits = c(-range,range) #you want centered around zero, so make larger # the ends
  ) +
  scale_x_continuous(breaks = c(33,34,35,36)) +
  labs(title = "Fig. 5 Replication Comparison") +
  theme_minimal() +
  theme(
    legend.title = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )
vuln_diff_map
```

```{r saving maps}
ggsave(
  here("results","figures","fig4comp_final.png"),
  plot = ac_diff_map,
  width = 8.5,
  height = 11,
  units = "in"
)
ggsave(
  here("results","figures","fig5comp_final.png"),
  plot = vuln_diff_map,
  width = 8.5,
  height = 11,
  units = "in"
)
```

```{r exporting comparison as geotiff}
write_stars(fig5comp, here("data", "derived", "public", "fig5diff.tif"), layer = "diff")
write_stars(fig5comp, here("data", "derived", "public", "fig5or.tif"), layer = "or")
write_stars(fig5comp, here("data", "derived", "public", "fig5rp.tif"), layer = "rp")
```